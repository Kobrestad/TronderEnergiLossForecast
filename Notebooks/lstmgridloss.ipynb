{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/grid-loss-time-series-dataset/test.csv\n/kaggle/input/grid-loss-time-series-dataset/train.csv\n/kaggle/input/grid-loss-time-series-dataset/test_backfilled_missing_data.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def shift_pandas_column(column, periods=24 * 7):\n    return column.shift(periods, fill_value=column.mean())\n\ndef get_datasets(\n    train_location=\"/kaggle/input/grid-loss-time-series-dataset/train.csv\",\n    test_location=\"/kaggle/input/grid-loss-time-series-dataset/test.csv\",\n):\n    columns_to_drop = [\n        \"grid1-loss-prophet-daily\",\n        \"grid1-loss-prophet-pred\",\n        \"grid1-loss-prophet-trend\",\n        \"grid1-loss-prophet-weekly\",\n        \"grid1-loss-prophet-yearly\",\n        \"grid2-load\",\n        \"grid2-loss\",\n        \"grid2-loss-prophet-daily\",\n        \"grid2-loss-prophet-pred\",\n        \"grid2-loss-prophet-trend\",\n        \"grid2-loss-prophet-weekly\",\n        \"grid2-loss-prophet-yearly\",\n        \"grid2_1-temp\",\n        \"grid2_2-temp\",\n        \"grid3-load\",\n        \"grid3-loss\",\n        \"grid3-loss-prophet-daily\",\n        \"grid3-loss-prophet-pred\",\n        \"grid3-loss-prophet-trend\",\n        \"grid3-loss-prophet-weekly\",\n        \"grid3-loss-prophet-yearly\",\n        \"grid3-temp\",\n    ]\n    raw_train = pd.read_csv(train_location, parse_dates=True)\n    raw_test = pd.read_csv(test_location, parse_dates=True)\n    pruned_train = raw_train.drop(columns=columns_to_drop)\n    pruned_test = raw_test.drop(columns=columns_to_drop)\n    pruned_train = raw_train.drop(columns=columns_to_drop).fillna( method='ffill')\n    pruned_test = raw_test.drop(columns=columns_to_drop).fillna( method='ffill')\n    \n\n    # get y values before shifting\n    train_y = pruned_train[\"grid1-loss\"].copy()\n    test_y = pruned_test[\"grid1-loss\"].copy()\n\n    # shift grid loss and load features 1 week to emulate real world delay of measurements\n    pruned_train[\"grid1-loss\"] = shift_pandas_column(pruned_train[\"grid1-loss\"])\n    pruned_train[\"grid1-load\"] = shift_pandas_column(pruned_train[\"grid1-load\"])\n    pruned_test[\"grid1-loss\"] = shift_pandas_column(pruned_test[\"grid1-loss\"])\n    pruned_test[\"grid1-load\"] = shift_pandas_column(pruned_test[\"grid1-load\"])\n\n    # give name to first column and change name on lagged load and loss\n    pruned_train.rename(columns={\"Unnamed: 0\": \"timestamp\"}, inplace=True)\n    pruned_test.rename(columns={\"Unnamed: 0\": \"timestamp\"}, inplace=True)\n    pruned_train.rename(columns={\"grid1-loss\": \"grid1-loss-lagged\"}, inplace=True)\n    pruned_test.rename(columns={\"grid1-loss\": \"grid1-loss-lagged\"}, inplace=True)\n    pruned_train.rename(columns={\"grid1-load\": \"grid1-load-lagged\"}, inplace=True)\n    pruned_test.rename(columns={\"grid1-load\": \"grid1-load-lagged\"}, inplace=True)\n    \n    \n    train = (pruned_train, train_y)\n    test = (pruned_test, test_y)\n\n    #return pruned_train, pruned_test\n    return train, test\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(pruned_train, train_y), (pruned_test, test_y) = get_datasets()","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime as dt\n\ndatelist_train = list(pruned_train['timestamp'])\ndatelist_train = [dt.datetime.fromisoformat(date) for date in datelist_train]\n\ndatelist_test = list(pruned_test['timestamp'])\ndatelist_test = [dt.datetime.fromisoformat(date) for date in datelist_test]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removes timestap beacuse bacause it can't be transformed to a float\nfloat_train = pruned_train.drop(columns=\"timestamp\")\ndataset_train = float_train.values.astype(float)\n\nfloat_test = pruned_test.drop(columns=\"timestamp\")\ndataset_test = float_test.values.astype(float)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n#makes and fits a scalar based on the X values in the training data\nsc = StandardScaler()\ntraining_set_scaled = sc.fit_transform(dataset_train)\n\n#makes and fits a scalar based on the Y values in the training data\nscTrainY = StandardScaler()\ntraining_set_Y_scaled = scTrainY.fit_transform(train_y.values.astype(float).reshape(-1, 1))\n\n#transformes the X and the Y values of the test data based on the fitted scaler form the training data\ntesting_set_Y_scaled = scTrainY.transform(test_y.values.astype(float).reshape(-1, 1))\ntesting_set_scaled = sc.transform(dataset_test)\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = []\ny_train = []\n\n#number of hours to predict into the future\nn_future = 36\n#number of days of each X value\nn_past = 24\n\n#makes a list of all X values, where 1 X values consists of the last \"n_past\" hours\n#makes a list of all Y values, where 1 Y value consists of 1 \"grid1-loss\", and is \"n_future\" furthere ahead that the last values in the coresponding X value\nfor i in range(n_past, len(training_set_scaled) - n_future +1):\n    X_train.append(training_set_scaled[i - n_past:i, 0:dataset_train.shape[1]])\n    y_train.append(training_set_Y_scaled[i + n_future - 1:i + n_future])\n\nX_train, y_train = np.array(X_train), np.array(y_train)\n\nprint('X_train shape == {}.'.format(X_train.shape))\nprint('y_train shape == {}.'.format(y_train.shape))\n","execution_count":7,"outputs":[{"output_type":"stream","text":"X_train shape == (17461, 24, 16).\ny_train shape == (17461, 1, 1).\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_test = []\ny_test = []\n\nfor i in range(n_past, len(testing_set_scaled) - n_future +1):\n    X_test.append(testing_set_scaled[i - n_past:i, 0:dataset_test.shape[1]])\n    y_test.append(training_set_Y_scaled[i + n_future - 1:i + n_future])\n\nX_test, y_test = np.array(X_test), np.array(y_test)\n\nprint('X_train shape == {}.'.format(X_test.shape))\nprint('y_train shape == {}.'.format(y_test.shape))","execution_count":8,"outputs":[{"output_type":"stream","text":"X_train shape == (4310, 24, 16).\ny_train shape == (4310, 1, 1).\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_combined = []\ny_combined = []\n\n#combines the test and traning data\n#this is used for adding test data to traning data later\ncombined_X_scaled = np.concatenate((training_set_scaled, testing_set_scaled))\ncombined_Y_scaled = np.concatenate((training_set_Y_scaled, testing_set_Y_scaled))\n\nfor i in range(n_past, len(combined_X_scaled) - n_future +1):\n    X_combined.append(combined_X_scaled[i - n_past:i, 0:dataset_test.shape[1] ])\n    y_combined.append(combined_Y_scaled[i + n_future - 1:i + n_future])\n\nX_combined, y_combined = np.array(X_combined), np.array(y_combined)\n\nprint('X_combined shape == {}.'.format(X_combined.shape))\nprint('y_combined shape == {}.'.format(y_combined.shape))\n\n#removes exsisting traning data\nX_combined = np.delete(X_combined, (range(17459)), axis=0)\ny_combined = np.delete(y_combined, (range(17459)), axis=0)\n\nprint('X_combined shape == {}.'.format(X_combined.shape))\nprint('y_combined shape == {}.'.format(y_combined.shape))","execution_count":9,"outputs":[{"output_type":"stream","text":"X_combined shape == (21830, 24, 16).\ny_combined shape == (21830, 1, 1).\nX_combined shape == (4371, 24, 16).\ny_combined shape == (4371, 1, 1).\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\n#two LSTM layers\nmodel.add(LSTM(units=32, return_sequences=True, input_shape=(n_past, dataset_train.shape[1])))\nmodel.add(LSTM(units=8, return_sequences=False))\n#added dropout to mitigtate overfitting\nmodel.add(Dropout(0.25))\n#1 output from dens layer\nmodel.add(Dense(units=1, activation='linear'))\nmodel.compile(optimizer = Adam(learning_rate=0.001), loss='mean_squared_error')\n\n#saves initial weigths, so that these can be loaded later, when resetting the traning \nmodel.save_weights('model.inital')","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#trains the model with 20 % of training data used as validation data\nhistory = model.fit(X_train, y_train, shuffle=True, epochs=10, verbose=1,validation_split=0.2, batch_size=96)","execution_count":12,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n146/146 [==============================] - 2s 11ms/step - loss: 0.2893 - val_loss: 0.1036\nEpoch 2/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.1845 - val_loss: 0.0862\nEpoch 3/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.1535 - val_loss: 0.0800\nEpoch 4/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.1352 - val_loss: 0.0893\nEpoch 5/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.1292 - val_loss: 0.0727\nEpoch 6/10\n146/146 [==============================] - 1s 7ms/step - loss: 0.1159 - val_loss: 0.0873\nEpoch 7/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.1126 - val_loss: 0.0962\nEpoch 8/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.1014 - val_loss: 0.0881\nEpoch 9/10\n146/146 [==============================] - 1s 5ms/step - loss: 0.1004 - val_loss: 0.0950\nEpoch 10/10\n146/146 [==============================] - 1s 6ms/step - loss: 0.0976 - val_loss: 0.0892\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'][0:], label='train', color=\"blue\")\nplt.plot(history.history['val_loss'][0:], label='test', color=\"red\")\nplt.legend(shadow=True)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<matplotlib.legend.Legend at 0x7f29a0412c90>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicts n_future(36) next hours for each X value in the test and traning data\npredictions_train = model.predict(X_train[n_past:])\npredictions_test = model.predict(X_test[n_past:])","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#invers transfomes the predicted train and test values back to normal values\ny_pred_train = scTrainY.inverse_transform(predictions_train)\ny_pred_test = scTrainY.inverse_transform(predictions_test)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import datetime\ndef datetime_to_timestamp(x):\n    return datetime.strptime(x.strftime('%Y%m%d %H%M%S'), '%Y%m%d %H%M%S')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#makes a datafram from the predicted values with a timestamp as the index\nprediction_train = pd.DataFrame(y_pred_train, columns=['grid-loss']).set_index(pd.Series(datelist_train[2 * n_past + n_future -1:]))\nprediction_test = pd.DataFrame(y_pred_test, columns=['grid-loss']).set_index(pd.Series(datelist_test[-24 + 2 * n_past + n_future -1:-24]))\n\nprediction_train.index = prediction_train.index.to_series().apply(datetime_to_timestamp)\nprediction_test.index = prediction_test.index.to_series().apply(datetime_to_timestamp)\n\n\nactualLossTrain = pd.DataFrame(train_y.values).set_index(pd.Series(datelist_train))\nactualLossTest = pd.DataFrame(test_y.values).set_index(pd.Series(datelist_test))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"allPredictions = []\n\nnumerOfIterations = 170\n\n#trains \"numerOfIterations\" number of neural networks to simulate the training of a new neural nettwork every day with new traning data \n#recomended to use GPU to run this, takes approxomently 30 min with GPU, as it is traning 170 neural nettworks\nfor i in range(numerOfIterations): #økt til resten av testdata\n\n    print(str(i+1) + \"/\" +  str(numerOfIterations))\n    #resests the weights of the model to the initial weights\n    model.load_weights('model.inital')\n    \n    #changes the verbose to 0(scilent) after 3 iterations\n    if (i>2):\n        history = model.fit(X_train, y_train, shuffle=True, epochs=10, verbose=0,validation_split=0.2, batch_size=96)\n    else:\n        history = model.fit(X_train, y_train, shuffle=True, epochs=10, verbose=2,validation_split=0.2, batch_size=96)\n    \n    #predicts the next 36 hours into the future based on the last 36 hours (n_future) starting on one week after the traning data\n    #the windows moves 24 hours per day\n    predictions_future = model.predict(X_test[24*7-n_future + 24*i:24*7 + 24*i])\n    \n    y_pred_future = scTrainY.inverse_transform(predictions_future)\n    \n    #sets the time index of the data, which is one week ahead of traning data \n    predictions_future_tmp = pd.DataFrame(y_pred_future, columns=['grid-loss']).set_index(pd.Series(datelist_test[7*24 + 24*i:7*24+n_future + 24*i]))\n    \n    #removes the first 12 hours that was predicted, as we are interested in 12 - 36 hours into the future\n    predictions_future_tmp = predictions_future_tmp.drop(pd.Series(datelist_test[7*24 + 24*i:7*24+12 + 24*i]))\n    allPredictions.append(predictions_future_tmp)\n    \n    #append 24 hours to training data\n    X_train = np.concatenate((X_train, X_combined[24*i : 24*i + 24]))\n    y_train = np.concatenate((y_train, y_combined[24*i : 24*i + 24]))\n    \n    \n\npredictions_future = pd.concat(allPredictions)\n","execution_count":18,"outputs":[{"output_type":"stream","text":"1/170\nEpoch 1/10\n146/146 - 1s - loss: 0.2821 - val_loss: 0.1099\nEpoch 2/10\n146/146 - 1s - loss: 0.1776 - val_loss: 0.0789\nEpoch 3/10\n146/146 - 1s - loss: 0.1551 - val_loss: 0.0692\nEpoch 4/10\n146/146 - 1s - loss: 0.1376 - val_loss: 0.0742\nEpoch 5/10\n146/146 - 1s - loss: 0.1324 - val_loss: 0.0812\nEpoch 6/10\n146/146 - 1s - loss: 0.1205 - val_loss: 0.0798\nEpoch 7/10\n146/146 - 1s - loss: 0.1147 - val_loss: 0.0862\nEpoch 8/10\n146/146 - 1s - loss: 0.1097 - val_loss: 0.0833\nEpoch 9/10\n146/146 - 1s - loss: 0.1082 - val_loss: 0.0981\nEpoch 10/10\n146/146 - 1s - loss: 0.1018 - val_loss: 0.0901\n2/170\nEpoch 1/10\n146/146 - 1s - loss: 0.2801 - val_loss: 0.1060\nEpoch 2/10\n146/146 - 1s - loss: 0.1796 - val_loss: 0.0888\nEpoch 3/10\n146/146 - 1s - loss: 0.1546 - val_loss: 0.0828\nEpoch 4/10\n146/146 - 1s - loss: 0.1430 - val_loss: 0.0772\nEpoch 5/10\n146/146 - 1s - loss: 0.1294 - val_loss: 0.0711\nEpoch 6/10\n146/146 - 1s - loss: 0.1221 - val_loss: 0.0974\nEpoch 7/10\n146/146 - 1s - loss: 0.1153 - val_loss: 0.0971\nEpoch 8/10\n146/146 - 1s - loss: 0.1108 - val_loss: 0.0905\nEpoch 9/10\n146/146 - 1s - loss: 0.1021 - val_loss: 0.0849\nEpoch 10/10\n146/146 - 1s - loss: 0.0986 - val_loss: 0.0939\n3/170\nEpoch 1/10\n146/146 - 1s - loss: 0.2798 - val_loss: 0.1109\nEpoch 2/10\n146/146 - 1s - loss: 0.1805 - val_loss: 0.0898\nEpoch 3/10\n146/146 - 1s - loss: 0.1558 - val_loss: 0.0964\nEpoch 4/10\n146/146 - 1s - loss: 0.1437 - val_loss: 0.0779\nEpoch 5/10\n146/146 - 1s - loss: 0.1306 - val_loss: 0.0796\nEpoch 6/10\n146/146 - 1s - loss: 0.1213 - val_loss: 0.0993\nEpoch 7/10\n146/146 - 1s - loss: 0.1167 - val_loss: 0.1151\nEpoch 8/10\n146/146 - 1s - loss: 0.1104 - val_loss: 0.0836\nEpoch 9/10\n146/146 - 1s - loss: 0.1062 - val_loss: 0.1045\nEpoch 10/10\n146/146 - 1s - loss: 0.1021 - val_loss: 0.1035\n4/170\n5/170\n6/170\n7/170\n8/170\n9/170\n10/170\n11/170\n12/170\n13/170\n14/170\n15/170\n16/170\n17/170\n18/170\n19/170\n20/170\n21/170\n22/170\n23/170\n24/170\n25/170\n26/170\n27/170\n28/170\n29/170\n30/170\n31/170\n32/170\n33/170\n34/170\n35/170\n36/170\n37/170\n38/170\n39/170\n40/170\n41/170\n42/170\n43/170\n44/170\n45/170\n46/170\n47/170\n48/170\n49/170\n50/170\n51/170\n52/170\n53/170\n54/170\n55/170\n56/170\n57/170\n58/170\n59/170\n60/170\n61/170\n62/170\n63/170\n64/170\n65/170\n66/170\n67/170\n68/170\n69/170\n70/170\n71/170\n72/170\n73/170\n74/170\n75/170\n76/170\n77/170\n78/170\n79/170\n80/170\n81/170\n82/170\n83/170\n84/170\n85/170\n86/170\n87/170\n88/170\n89/170\n90/170\n91/170\n92/170\n93/170\n94/170\n95/170\n96/170\n97/170\n98/170\n99/170\n100/170\n101/170\n102/170\n103/170\n104/170\n105/170\n106/170\n107/170\n108/170\n109/170\n110/170\n111/170\n112/170\n113/170\n114/170\n115/170\n116/170\n117/170\n118/170\n119/170\n120/170\n121/170\n122/170\n123/170\n124/170\n125/170\n126/170\n127/170\n128/170\n129/170\n130/170\n131/170\n132/170\n133/170\n134/170\n135/170\n136/170\n137/170\n138/170\n139/170\n140/170\n141/170\n142/170\n143/170\n144/170\n145/170\n146/170\n147/170\n148/170\n149/170\n150/170\n151/170\n152/170\n153/170\n154/170\n155/170\n156/170\n157/170\n158/170\n159/170\n160/170\n161/170\n162/170\n163/170\n164/170\n165/170\n166/170\n167/170\n168/170\n169/170\n170/170\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = \"170_2.csv\"\n\npredictions_future.to_csv(filename, index=True)\n\n#predictions_future2 = pd.read_csv(\"../input/60days/60Days.csv\",index_col = 0, parse_dates=True)\n#predictions_future2.shape","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotGraph(start_date, end_date, actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test):\n    \n    #plt.figure(1, figsize=(28, 3))\n    \n    plt.plot(actualLossTrain.loc[start_date:end_date], label=\"ActualTrain\")\n    plt.plot(actualLossTest.loc[start_date:end_date], label=\"ActualTest\")\n\n    plt.plot(prediction_train.loc[start_date:end_date], label=\"trainPredict\")\n    plt.plot(predictions_future.loc[start_date:end_date], label=\"futurePredict\")\n    #plt.plot(prediction_test.loc[start_date:end_date], label=\"testPredict\")","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotPredictions(start_date, end_date, actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test):\n    \n    plt.figure(1, figsize=(10, 3))\n    plt.title(\"Predicted loss and actual loss on test set\")\n    #plt.plot(actualLossTrain.loc[start_date:end_date], label=\"ActualTrain\")\n    plt.plot(actualLossTest.loc[start_date:end_date], label=\"ActualTest\", color=\"green\")\n\n    #plt.plot(prediction_train.loc[start_date:end_date], label=\"trainPredict\")\n    plt.plot(predictions_future.loc[start_date:end_date], label=\"PredictedTest\", color=\"orange\")\n    #plt.plot(prediction_test.loc[start_date:end_date], label=\"testPredict\")\n    plt.grid(True)\n    plt.legend(shadow=True)\n    plt.xlabel('Month (m)')\n    plt.ylabel('Grid loss (MWh)')\n    plt.show()","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotPredictions('2019-12-09', '2020-05-26', actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test)","execution_count":22,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'actualLossTimeFrame' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-e8ef6b6ac8fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotPredictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2019-12-09'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'2020-05-26'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactualLossTimeFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactualLossTimeFrameTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_future\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'actualLossTimeFrame' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotGraph('2019-11-20', '2019-12-20', actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotGraph('2019-12-06', '2019-12-13', actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotGraph('2020-01-15', '2020-01-20', actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotGraph('2017-01-27', '2020-06-03', actualLossTrain, actualLossTest, prediction_train, predictions_future, prediction_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_absolute_error as mae, mean_squared_error as mse, median_absolute_error as medae\n\ndef runEvaluation(y_true, y_pred):\n    \n    metrics = [mae, root_mean_squared_error, mean_absolute_percentage_error]\n    return [calc(y_true, y_pred) for calc in metrics]\n\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n\ndef root_mean_squared_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"start_date_train = '2018-02-01'\nevaluation = runEvaluation(prediction_train.loc[start_date_train:], actualLossTrain.loc[start_date_train:])\nprint(evaluation)\n\n\nstart_date_test = '2020-01-01'\nend_date_test = '2020-05-01'\nevaluationTest = runEvaluation(prediction_test.loc[start_date_test:end_date_test], actualLossTest.loc[start_date_test:end_date_test])\nprint(evaluationTest)\n\n\nstart_date_predict = str(predictions_future[0:1].index)[16:35]\nend_date_predict = str(predictions_future[-1:].index)[16:35]\nevaluationPrediction = runEvaluation(predictions_future.loc[start_date_predict:end_date_predict], actualLossTest.loc[start_date_predict:end_date_predict])\nprint(evaluationPrediction)\n\n#print(str(predictions_future[-1:].index)[16:35])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}